{
    "research": [
      {
        "title": "MRMAC: Mixed Reality Multi-user Asymmetric Collaboration",
        "slug": "mrmac",
        "slogan": "",
        "desc": "We present MRMAC, a Mixed Reality Multi-user Asymmetric Collaboration system that allows remote users to teleport virtually into a real-world collaboration space to communicate and collaborate with local users. Our system enables telepresence for remote users by live-streaming the physical environment of local users using a 360-degree camera while blending 3D virtual assets into the mixed-reality collaboration space. Our novel client-server architecture enables asymmetric collaboration for multiple AR and VR users and incorporates avatars, view controls, as well as synchronized low-latency audio, video, and asset streaming. We evaluated our implementation with two baseline conditions: conventional 2D and standard 360-degree videoconferencing. Results show that MRMAC outperformed both baselines in inducing a sense of presence, improving task performance, usability, and overall user preference, demonstrating its potential for immersive multi-user telecollaboration.",
        "thumbnail": "mrmac/mrmac-teaser.png",
        "paper_thumb": "mrmac/mrmac-pdf.jpg",
        "journal": "IEEE International Symposium on Mixed and Augmented Reality (ISMAR 2023)",
        "authors": [
            {
                "name": "Faisal Zaman",
                "url": "https://jquery404.github.io",
                "affiliation": "CMIC, Victoria University of Wellington"
            },
            {
                "name": "Craig Anslow",
                "url": "https://homepages.ecs.vuw.ac.nz/~craig/",
                "affiliation": "ECS, Victoria University of Wellington"
            },
            {
                "name": "Andrew Chalmers",
                "url": "https://people.wgtn.ac.nz/andrew.chalmers",
                "affiliation": "CMIC, Victoria University of Wellington"
            },
            {
                "name": "Taehyun Rhee",
                "url": "https://people.wgtn.ac.nz/taehyun.rhee",
                "affiliation": "CMIC, Victoria University of Wellington"
            }
        ],
        "url": "assets/papers/5663557.997664.pdf",
        "file_info": "PDF, 7.6mb",
        "tags": "vr, ar, 360-video, collaboration",
        "bibtex": "@inproceedings{zaman2023mrmac,\ntitle={MRMAC: Mixed Reality Multi-user Asymmetric Collaboration},\nauthor={Zaman, Faisal and Anslow, Craig and Chalmers, Andrew and Rhee, Taehyun James},\nbooktitle={Proceedings of the IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},\npages={1--10},\nyear={2023}}",
        "gallery": [
            {
                "header": "Submission Video",
                "type": "video",
                "ratio": "landscape",
                "url": "https://www.youtube.com/embed/ReZbxpT1LqE"
            },
            {
                "header": "Presentation Video",
                "type": "video",
                "ratio": "landscape",
                "url": "https://www.youtube.com/embed/rRfPdnijaiI"
            }
        ],
        "slides": [
            {
                "slide_thumb": "mrmac/mrmac_10m_slides.png",
                "title": "10min ISMAR talk",
                "file_info": "PDF, 1.8mb",
                "pdf": "mrmac/ISMAR2023_MRMAC_slides.pdf"
            }
        ]
      },
      {
        "title": "Vicarious: Context-aware Viewpoints Selection for Mixed Reality Collaboration",
        "slug": "vicarious",
        "slogan": "Why work remotely when you can work Vicariously",
        "desc": "Mixed-perspective, combining egocentric (first-person) and exocentric (third-person) viewpoints, have been shown to improve the collaborative experience in remote settings. Such experiences allow remote users to switch between different viewpoints to gain alternative perspectives of the remote space. However, existing systems lack seamless selection and transition between multiple perspectives that better fit the task at hand. To address this, we present a new approach called Vicarious, which simplifies and automates the selection between egocentric and exocentric viewpoints. Vicarious employs a context-aware method for dynamically switching or highlighting the optimal viewpoint based on user actions and the current context. To evaluate the effectiveness of the viewpoint selection method, we conducted a user study (n = 27) using an asymmetric AR-VR setup where users performed remote collaboration tasks under four distinct conditions: No-view, Manual, Guided, and Automatic selection. The results showed that Guided and Automatic viewpoint selection improved usersâ€™ understanding of the task space and task performance, and reduced cognitive load compared to Manual or No-view selection. The results also suggest that the asymmetric setup had minimal impact on spatial and social presence, except for differences in task load and preference. Based on these findings, we provide design implications for future research in mixed reality collaboration.",
        "thumbnail": "vicarious/teaser.jpg",
        "paper_thumb": "vicarious/paper_thumb.jpg",
        "journal": "ACM Symposium on Virtual Reality Software and Technology (VRST 2023)",
        "authors": [
            {
                "name": "Faisal Zaman",
                "url": "https://jquery404.github.io",
                "affiliation": "CMIC, Victoria University of Wellington"
            },
            {
                "name": "Craig Anslow",
                "url": "https://homepages.ecs.vuw.ac.nz/~craig/",
                "affiliation": "ECS, Victoria University of Wellington"
            },
            {
                "name": "Taehyun Rhee",
                "url": "https://people.wgtn.ac.nz/taehyun.rhee",
                "affiliation": "CMIC, Victoria University of Wellington"
            }
        ],
        "url": "assets/papers/3677878.996443.pdf",
        "file_info": "PDF, 18.4mb",
        "tags": "vr, ar, 360-video, viewpoint sharing, collaboration",
        "bibtex": "@inproceedings{zaman2023vicarious,\ntitle={Vicarious: Context-aware Viewpoints Selection for Mixed Reality Collaboration},\nauthor={Zaman, Faisal and Anslow, Craig and Rhee, Taehyun James},\nbooktitle={Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},\npages={1--11},\nyear={2023}}",
        "gallery": [
            {
                "header": "Submission Video",
                "type": "video",
                "ratio": "landscape",
                "url": "https://www.youtube.com/embed/peyOakF4dmg"
            },
            {
                "header": "Presentation Video",
                "type": "video",
                "ratio": "landscape",
                "url": "https://www.youtube.com/embed/QYR45GyM4Iw"
            }
        ],
        "slides": [
            {
                "slide_thumb": "vicarious/slide_thumb.jpg",
                "title": "15min VRST talk",
                "file_info": "PDF, 1.2mb",
                "pdf": "vicarious/VRST2023_Vicarious_slides.pdf"
            }
        ]
      },
      {
        "title": "Real-time Stage Modelling and Visual Effects for Live Performances.",
        "slug": "rtstage",
        "slogan": "Why work remotely when you can work Vicariously",
        "desc": "We present a novel live platform enhancing stage performances with real-time visual effects. Our demo showcases real-time 3D modeling, rendering and blending of assets, and interaction between real and virtual performers. We demonstrate our platform's capabilities with a mixed reality performance featuring virtual and real actors engaged with in-person audiences.",
        "thumbnail": "rtstage/teaser.jpg",
        "paper_thumb": "rtstage/paper_thumb.jpg",
        "journal": "ACM SIGGRAPH Real-Time Live! (SIGGRAPH 2023)",
        "award": "Audience Choice Award",
        "authors": [
            {
                "name": "Taehyun Rhee",
                "url": "https://people.wgtn.ac.nz/taehyun.rhee",
                "affiliation": "CMIC, Victoria University of Wellington"
            },
            {
                "name": "Andrew Chalmers",
                "url": "https://people.wgtn.ac.nz/andrew.chalmers",
                "affiliation": "CMIC, Victoria University of Wellington"
            },
            {
                "name": "Faisal Zaman",
                "url": "https://jquery404.github.io",
                "affiliation": "CMIC, Victoria University of Wellington"
            },
            {
                "name": "Anna Stangnes",
                "url": "https://www.wgtn.ac.nz/cmic",
                "affiliation": "CMIC, Victoria University of Wellington"
            },
            {
                "name": "Vic Roberts",
                "url": "https://www.wgtn.ac.nz/cmic",
                "affiliation": "CMIC, Victoria University of Wellington"
            }
        ],
        "url": "assets/papers/3588430.3597245.pdf",
        "file_info": "PDF, 3.4mb",
        "tags": "live visual effects, real-time performance, mixed reality, televerse",
        "bibtex": "@incollection{rhee2023real,\ntitle={Real-time Stage Modelling and Visual Effects for Live Performances},\nauthor={Rhee, Taehyun and Chalmers, Andrew and Zaman, Faisal and Stangnes, Anna and Roberts, Vic},\nbooktitle={ACM SIGGRAPH 2023 Real-Time Live!},\npages={1--2},\nyear={2023}}",
        "gallery": [
            {
                "header": "Presentation",
                "type": "video",
                "ratio": "landscape",
                "url": "https://www.youtube.com/embed/7dhnX0XRwew"
            }
        ],
        "slides": [
            
        ],

        "articles": [
            {
                "header": "Step Into the Virtual Arena With Real-time Stage Modeling and Visual Effects",
                "url": "https://blog.siggraph.org/2023/10/step-into-the-virtual-arena-with-real-time-stage-modeling-and-visual-effects.html/"
            },
            {
                "header": "CMIC wins Audience Choice Award at Real-Time Live! SIGGRAPH 2023",
                "url": "https://www.wgtn.ac.nz/cmic/news/real-time-live-wins-peoples-choice-award-at-siggraph-2023"
            },
            {
                "header": "University project wins award at international computer graphics conference",
                "url": "https://www.wgtn.ac.nz/engineering/news/university-project-wins-award-at-international-computer-graphics-conference"
            }
        ]
      }
    ]
}